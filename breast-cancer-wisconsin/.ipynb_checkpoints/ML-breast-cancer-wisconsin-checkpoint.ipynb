{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " df = pd.read_csv('data/wdbc.data', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('rows, columns:', (569, 32))\n"
     ]
    }
   ],
   "source": [
    "print('rows, columns:', df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1      2      3       4       5        6        7       8   \\\n",
       "0    842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
       "1    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
       "2  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
       "3  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
       "4  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
       "\n",
       "        9    ...        22     23      24      25      26      27      28  \\\n",
       "0  0.14710   ...     25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119   \n",
       "1  0.07017   ...     24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416   \n",
       "2  0.12790   ...     23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504   \n",
       "3  0.10520   ...     14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869   \n",
       "4  0.10430   ...     22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000   \n",
       "\n",
       "       29      30       31  \n",
       "0  0.2654  0.4601  0.11890  \n",
       "1  0.1860  0.2750  0.08902  \n",
       "2  0.2430  0.3613  0.08758  \n",
       "3  0.2575  0.6638  0.17300  \n",
       "4  0.1625  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = df.loc[:, 2:].values\n",
    "y = df.loc[:, 1].values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.947\n"
     ]
    }
   ],
   "source": [
    "# Check with logistic Regression\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe_logistic_regression =  Pipeline([('scl', StandardScaler()),\n",
    "                                      ('pca', PCA(n_components=2)),\n",
    "                                      ('clf', LogisticRegression(random_state=1))])\n",
    "\n",
    "pipe_logistic_regression.fit(X_train, y_train)\n",
    "print('Test Accuracy: %.3f' % pipe_logistic_regression.score(X_test, y_test))\n",
    "y_pred = pipe_logistic_regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [ 0.89130435  0.97826087  0.97826087  0.91304348  0.93478261  0.97777778\n",
      "  0.93333333  0.95555556  0.97777778  0.95555556]\n",
      "CV accuracy: 0.950 +/- 0.029\n"
     ]
    }
   ],
   "source": [
    "# 10-cross validation test with range of variation across mean\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(estimator=pipe_logistic_regression,\n",
    "                         X=X_train,\n",
    "                         y=y_train,\n",
    "                         cv=10,\n",
    "                         n_jobs=1)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978021978022\n",
      "{'clf__C': 0.1, 'clf__kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# To use SVM instead of logistic Regression with parameter tuning to check if result got better\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "    \n",
    "pipe_svc = Pipeline([('scl', StandardScaler()),\n",
    "            ('clf', SVC(random_state=1))])\n",
    "\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "param_grid = [{'clf__C': param_range, \n",
    "               'clf__kernel': ['linear']},\n",
    "              {   'clf__C': param_range, \n",
    "                  'clf__gamma': param_range, \n",
    "                  'clf__kernel': ['rbf']}\n",
    "             ]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_svc, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  cv=10,\n",
    "                  n_jobs=-1)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.965\n"
     ]
    }
   ],
   "source": [
    "clf = gs.best_estimator_\n",
    "clf.fit(X_train, y_train)\n",
    "print('Test accuracy: %.3f' % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [ 0.93478261  1.          0.93478261  0.95652174  1.          1.\n",
      "  0.97777778  0.95555556  1.          0.95555556]\n",
      "CV accuracy: 0.971 +/- 0.026\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=pipe_svc,\n",
    "                         X=X_train,\n",
    "                         y=y_train,\n",
    "                         cv=10,\n",
    "                         n_jobs=1)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In the first try SVM fits with better result as compared to logistic regression, if SVM didnt worked then we will try decison tree, random forest, xg-boost in a similar way to svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71  1]\n",
      " [ 2 40]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pipe_svc.fit(X_train, y_train)\n",
    "y_pred = pipe_svc.predict(X_test)\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKwAAACsCAYAAADmMUfYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njyBKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6514469890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
    "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
    "\n",
    "plt.xlabel('predicted label')\n",
    "plt.ylabel('true label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.976\n",
      "Recall: 0.952\n",
      "F1: 0.964\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "print('Precision: %.3f' % precision_score(y_true=y_test, y_pred=y_pred))\n",
    "print('Recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred))\n",
    "print('F1: %.3f' % f1_score(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC area under curve: 0.969\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "print('ROC area under curve: %.3f' % roc_auc_score(y_true=y_test, y_score=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
